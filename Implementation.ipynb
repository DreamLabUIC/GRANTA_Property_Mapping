{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b458d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle \n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eaaea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Data - Notice the order of the properties and the units. \n",
    "\n",
    "Strength_columns = [\n",
    "    \"Yield strength (elastic limit) (ksi)\", # i = 0\n",
    "    \"Tensile strength (ksi)\", # i = 1 \n",
    "    \"Compressive strength (ksi)\", # i = 2 \n",
    "    \"Flexural strength (modulus of rupture) (ksi)\", # i = 3 \n",
    "    \"Hardness - Vickers (HV)\", # i = 4 \n",
    "    \"Fatigue strength at 10^7 cycles (ksi)\", # i = 5 \n",
    "    \"Thermal shock resistance (°F)\" # i = 6 \n",
    "]\n",
    "\n",
    "Mechanical_columns = [\n",
    "    \"Density (lb/in³)\",  # i = 0\n",
    "    \"Young's modulus (10⁶ psi)\",  # i = 1\n",
    "    \"Flexural modulus (10⁶ psi)\",  # i = 2\n",
    "    \"Shear modulus (10⁶ psi)\",  # i = 3\n",
    "    \"Bulk modulus (10⁶ psi)\",  # i = 4\n",
    "    \"Poisson's ratio\"  # i = 5\n",
    "]\n",
    "\n",
    "Thermal_columns = [\n",
    "    \"Melting point (°F)\",  # i = 0\n",
    "    \"Thermal conductivity (BTU/hr·ft·°F)\",  # i = 1\n",
    "    \"Specific heat capacity (BTU/lb·°F)\",  # i = 2\n",
    "    \"Thermal expansion coefficient (µstrain/°F)\",  # i = 3\n",
    "    \"Latent heat of fusion (BTU/lb)\"  # i = 4\n",
    "]\n",
    "\n",
    "Processing_columns = [\n",
    "    \"Annealed\",                \n",
    "    \"Normalized\",              \n",
    "    \"Tempered\",                \n",
    "    \"Aged\",                   \n",
    "    \"Tempering Temperature\",  \n",
    "    \"Aging Temperature\",      \n",
    "    \"Cold Work\",              \n",
    "    \"Cooling Catalog\"  \n",
    "]\n",
    "\n",
    "\n",
    "# Define the data rows\n",
    "Strength_data = [\n",
    "    [30.5, 58.0, 30.6, 30.5, 235, 26.1, 219],\n",
    "    [112.0, 130.0, 112.0, 112.0, 275, 57.6, 610],\n",
    "    [82.9, 127.0, 110.0, 82.9, 460, 78.6, 448],\n",
    "    [91.4, 116.0, 92.7, 91.4, 265, 44.1, 660],\n",
    "    [39.8, 60.8, 39.7, 39.8, 173, 42.5, 241],\n",
    "    [242.0, 264.0, 242.0, 242.0, 505, 94.4, 1330]\n",
    "]\n",
    "\n",
    "Mechanical_data = [\n",
    "    [0.269, 27.0, 27.0, 12.0, 19.1, 0.265],\n",
    "    [0.285, 31.3, 31.3, 12.3, 25.5, 0.295],\n",
    "    [0.284, 30.0, 30.0, 11.7, 21.7, 0.281],\n",
    "    [0.26, 25.5, 25.5, 10.2, 19.4, 0.28],\n",
    "    [0.285, 30.5, 30.5, 11.6, 28.2, 0.333],\n",
    "    [0.285, 30.7, 30.7, 12.0, 25.1, 0.295]\n",
    "]\n",
    "\n",
    "Thermal_data = [\n",
    "    [2470, 24.3, 0.133, 7.78, 118],\n",
    "    [2760, 27.7, 0.119, 7.22, 120],\n",
    "    [2620, 11.1, 0.109, 7.04, 123],\n",
    "    [2280, 19.6, 0.118, 6.94, 118],\n",
    "    [2780, 32.5, 0.121, 6.62, 118],\n",
    "    [2740, 26.6, 0.119, 7.22, 120]\n",
    "]\n",
    "\n",
    "Processing_data = [\n",
    "    [0, 0, 0, 0, 27, 27, 0.0, 1],\n",
    "    [1, 0, 1, 0, 650, 27, 0.0, 3],\n",
    "    [1, 0, 0, 1, 27, 620, 0.0, 1],\n",
    "    [1, 0, 1, 0, 600, 27, 0.0, 1],\n",
    "    [0, 1, 0, 0, 27, 27, 0.0, 1],\n",
    "    [1, 0, 1, 0, 315, 27, 0.0, 4]\n",
    "]\n",
    "\n",
    "\n",
    "# Create the DataFrame\n",
    "Strength_Properties = pd.DataFrame(Strength_data, columns=Strength_columns)\n",
    "Mechanical_Properties = pd.DataFrame(Mechanical_data, columns=Mechanical_columns)\n",
    "Thermal_Properties = pd.DataFrame(Thermal_data, columns=Thermal_columns)\n",
    "Processing_Properties = pd.DataFrame(Processing_data, columns=Processing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75c3c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load All Alloy Scalers - Based on ANSYS Granta Dataset\n",
    "scaler_Mechanical_Properties = joblib.load('scaler/scaler_Mechanical_Properties.pkl')\n",
    "scaler_Thermal_Properties = joblib.load('scaler/scaler_Thermal_Properties.pkl')\n",
    "scaler_Strength_Properties = joblib.load('scaler/scaler_Strength_Properties.pkl')\n",
    "\n",
    "# Load Fe-specific Scalers - Based on ANSYS Granta Dataset\n",
    "Fe_scaler_Mechanical_Properties = joblib.load('scaler/Fe_scaler_Mechanical_Properties.pkl')\n",
    "Fe_scaler_Thermal_Properties = joblib.load('scaler/Fe_scaler_Thermal_Properties.pkl')\n",
    "Fe_scaler_Strength_Properties = joblib.load('scaler/Fe_scaler_Strength_Properties.pkl')\n",
    "Fe_scaler_processing = joblib.load('scaler/Fe_scaler_processing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f862ae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dream Lab\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dream Lab\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dream Lab\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dream Lab\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dream Lab\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dream Lab\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dream Lab\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the points based on the loaded scalers\n",
    "Mechanical_Normalized = scaler_Mechanical_Properties.transform(Mechanical_Properties.values)\n",
    "Thermal_Normalized = scaler_Thermal_Properties.transform(Thermal_Properties.values)\n",
    "Strength_Normalized = scaler_Strength_Properties.transform(Strength_Properties.values)\n",
    "\n",
    "# Normalizing the points based on the loaded Fe_scalers\n",
    "Fe_Mechanical_Normalized = Fe_scaler_Mechanical_Properties.transform(Mechanical_Properties.values)\n",
    "Fe_Thermal_Normalized = Fe_scaler_Thermal_Properties.transform(Thermal_Properties.values)\n",
    "Fe_Strength_Normalized = Fe_scaler_Strength_Properties.transform(Strength_Properties.values)\n",
    "Fe_Processing_Normalized = Fe_scaler_processing.transform(Processing_Properties.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18156c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIn the repository, you will find the trained models based on the dataset. The dataset cannot be published because it is owned by ANSYS. However, \\nthe models are trained based on that data. Each model takes a set of properties from the above (X) and outputs only a single normalized property (Y_predicted). \\n\\nIt is required to unnormalize the predicted property, so make sure to choose the correct scaler in the unnormalization step, with the correct value of 'i', which \\ncorresponds to the predicted property based on the 'i_s' given at the top when the columns were defined.\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine learining Models.\n",
    "'''\n",
    "In the repository, you will find the trained models based on the dataset. The dataset cannot be published because it is owned by ANSYS. However, \n",
    "the models are trained based on that data. Each model takes a set of properties from the above (X) and outputs only a single normalized property (Y_predicted). \n",
    "\n",
    "It is required to unnormalize the predicted property, so make sure to choose the correct scaler in the unnormalization step, with the correct value of 'i', which \n",
    "corresponds to the predicted property based on the 'i_s' given at the top when the columns were defined.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaded59",
   "metadata": {},
   "source": [
    "## All Alloys \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ccd6a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "## Neural Network (NN) - Predicting Bulk Modulus from Thermal Properties\n",
    "\n",
    "X = Thermal_Normalized  # Define the input set of properties: {Thermal_Normalized, Mechanical_Normalized, Strength_Normalized}\n",
    "scaler = scaler_Mechanical_Properties  # Choose the scaler corresponding to the target property: {scaler_Mechanical_Properties, scaler_Thermal_Properties, scaler_Strength_Properties}\n",
    "i = 4  # Index 'i' for Bulk Modulus in the Mechanical Properties scaler\n",
    "NN = load_model(\"Models/Mechanical_from_Thermal/NN/Bulk_modulus.h5\") # Load the trained model corresponding to the target property and input set\n",
    "\n",
    "# Predict and unnormalize the target property\n",
    "Y_predicted_Normalized = NN.predict(X)\n",
    "Y_predicted = Y_predicted_Normalized * scaler.scale_[i] + scaler.mean_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "505a39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geometric Harmonics (GH) - Predicting Melting Point from Mechanical Properties\n",
    "\n",
    "X = Mechanical_Normalized  # Define the input set of properties: {Thermal_Normalized, Mechanical_Normalized, Strength_Normalized}\n",
    "scaler = scaler_Thermal_Properties  # Choose the scaler corresponding to the target property: {scaler_Mechanical_Properties, scaler_Thermal_Properties, scaler_Strength_Properties}\n",
    "i = 0  # Index 'i' for Melting Point in the Thermal Properties scaler\n",
    "\n",
    "# Load the trained GH model corresponding to the target property and input set\n",
    "filename = \"Models/Thermal_from_Mechanical/GH/Melting_point.pkl\"\n",
    "with open(filename, \"rb\") as f:\n",
    "    gh_interpolant = pickle.load(f)\n",
    "\n",
    "# Predict and unnormalize the target property\n",
    "Y_predicted_Normalized = gh_interpolant.predict(X)\n",
    "Y_predicted = Y_predicted_Normalized * scaler.scale_[i] + scaler.mean_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d66d6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double Diffusion Maps (DDM) - Predicting Young's Modulus from Thermal Properties\n",
    "\n",
    "X = Thermal_Normalized  # Define the input set of properties: {Thermal_Normalized, Mechanical_Normalized, Strength_Normalized}\n",
    "scaler = scaler_Mechanical_Properties  # Choose the scaler corresponding to the target property: {scaler_Mechanical_Properties, scaler_Thermal_Properties, scaler_Strength_Properties}\n",
    "i = 1  # Index 'i' for Young's Modulus in the Mechanical Properties scaler\n",
    "\n",
    "# Load the trained DDM models (First step: Diffusion Map, Second step: Geometric Harmonics)\n",
    "filename1 = \"Models/Mechanical_from_Thermal/DDM/Young_s_modulusDM.pkl\"  # First step DM\n",
    "filename2 = \"Models/Mechanical_from_Thermal/DDM/Young_s_modulusGH.pkl\"  # Second step GH\n",
    "\n",
    "with open(filename1, \"rb\") as f:\n",
    "    DM_interpolant = pickle.load(f)\n",
    "\n",
    "with open(filename2, \"rb\") as f:\n",
    "    GH_interpolant = pickle.load(f)\n",
    "\n",
    "# Predict and unnormalize the target property\n",
    "psi_predicted = DM_interpolant.predict(X)\n",
    "Y_predicted_Normalized = GH_interpolant.predict(psi_predicted)\n",
    "Y_predicted = Y_predicted_Normalized * scaler.scale_[i] + scaler.mean_[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ac943",
   "metadata": {},
   "source": [
    "## Fe_Alloys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85456c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "## Neural Network (NN) - Predicting Yield Strength from Thermal Properties and Processing Conditions\n",
    "\n",
    "X = np.concatenate([Fe_Thermal_Normalized, Fe_Processing_Normalized], axis=1)   # Define the input set of properties: {Fe_Thermal_Normalized, Fe_Mechanical_Normalized}, in addition to Fe_Processing_Normalized\n",
    "scaler = Fe_scaler_Strength_Properties  # Choose the scaler corresponding to the target property: {Fe_scaler_Mechanical_Properties, Fe_scaler_Thermal_Properties, Fe_scaler_Strength_Properties}\n",
    "i = 0  # Index 'i' for Yield Strength in the Strength Properties scaler\n",
    "# Load the trained NN model corresponding to the target property and input set\n",
    "NN = load_model(\"Models/Fe_Strength_from_Thermal/NN/Yield_strength.h5\")\n",
    "\n",
    "# Predict and unnormalize the target property\n",
    "Y_predicted_Normalized = NN.predict(X)\n",
    "Y_predicted = Y_predicted_Normalized * scaler.scale_[i] + scaler.mean_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d4b50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Geometric Harmonics (GH) - Predicting Yield Strength from Mechanical Properties and Processing Conditions\n",
    "\n",
    "X = np.concatenate([Fe_Mechanical_Normalized, Fe_Processing_Normalized], axis=1)   # Define the input set of properties: {Fe_Thermal_Normalized, Fe_Mechanical_Normalized}, in addition to Fe_Processing_Normalized\n",
    "scaler = Fe_scaler_Strength_Properties  # Choose the scaler corresponding to the target property: {Fe_scaler_Mechanical_Properties, Fe_scaler_Thermal_Properties, Fe_scaler_Strength_Properties}\n",
    "i = 0  # Index 'i' for Yield Strength in the Strength Properties scaler\n",
    "\n",
    "# Load the trained GH model corresponding to the target property and input set\n",
    "filename = \"Models/Fe_Strength_from_Mechancial/GH/Yield_strength.pkl\"\n",
    "with open(filename, \"rb\") as f:\n",
    "    gh_interpolant = pickle.load(f)\n",
    "\n",
    "# Predict and unnormalize the target property\n",
    "Y_predicted_Normalized = gh_interpolant.predict(X)\n",
    "Y_predicted = Y_predicted_Normalized * scaler.scale_[i] + scaler.mean_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "186935b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double Diffusion Maps (DDM) - Predicting Tensile Strength from Thermal Properties and Processing Conditions\n",
    "\n",
    "X = np.concatenate([Fe_Thermal_Normalized, Fe_Processing_Normalized], axis=1) # Define the input set of properties: {Fe_Thermal_Normalized, Fe_Mechanical_Normalized}, in addition to Fe_Processing_Normalized\n",
    "scaler = Fe_scaler_Strength_Properties  # Choose the scaler corresponding to the target property: {Fe_scaler_Mechanical_Properties, Fe_scaler_Thermal_Properties, Fe_scaler_Strength_Properties}\n",
    "i = 1  # Index 'i' for Tensile Strength in the Strength Properties scaler\n",
    "\n",
    "# Load the trained DDM models (First step: Diffusion Map, Second step: Geometric Harmonics)\n",
    "filename1 = \"Models/Fe_Strength_from_Thermal/DDM/Tensile_strengthDM.pkl\"  # First step DM\n",
    "filename2 = \"Models/Fe_Strength_from_Thermal/DDM/Tensile_strengthGH.pkl\"  # Second step GH\n",
    "\n",
    "with open(filename1, \"rb\") as f:\n",
    "    DM_interpolant = pickle.load(f)\n",
    "\n",
    "with open(filename2, \"rb\") as f:\n",
    "    GH_interpolant = pickle.load(f)\n",
    "\n",
    "# Predict and unnormalize the target property\n",
    "psi_predicted = DM_interpolant.predict(X)\n",
    "Y_predicted_Normalized = GH_interpolant.predict(psi_predicted)\n",
    "Y_predicted = Y_predicted_Normalized * scaler.scale_[i] + scaler.mean_[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
